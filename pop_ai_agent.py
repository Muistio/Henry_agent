#!/usr/bin/env python3
"""
Pop AI Advisor â€“ Personal Agent Demo (Streamlit)
------------------------------------------------
Kevyt Streamlit-sovellus, jolla POP Pankin rekry voi jutella AI-agentin kanssa.
NÃ¤yttÃ¤Ã¤:
  â€¢ Persona + keskustelumuisti
  â€¢ RAG tyÃ¶paikkailmoituksesta + (valinnaisesti) ladatuista tiedostoista
  â€¢ Pienet tyÃ¶kalut (AI-ideat, roadmap-bulletit, AI governance -checklist)

Pika-aloitus:
1) pip install -U -r requirements.txt
2) export OPENAI_API_KEY=...  (tai aseta sivupalkissa)
3) streamlit run pop_ai_agent.py
"""

import io
import os
from dataclasses import dataclass
from typing import List, Dict, Any, Optional, Callable

import numpy as np
import streamlit as st
from openai import OpenAI
from pypdf import PdfReader

# -------------------------------
# Perusasetukset
# -------------------------------
DEFAULT_MODEL = "gpt-4o-mini"
EMBED_MODEL = "text-embedding-3-small"
APP_NAME = "Pop AI advisor â€“ agent"

# Ei henkilÃ¶kohtaisia tietoja
ABOUT_ME = """"""

# TyÃ¶paikkailmoitus (ydin)
JOB_TEXT = """
Haemme POP Pankkikeskukseen: AI Advisor (AI-asiantuntijaa)

AI Advisorin keskeiset tehtÃ¤vÃ¤t:
- Suunnittelet ja koordinoit pankkiryhmÃ¤n tekoÃ¤lykehitystÃ¤ tiiviissÃ¤ yhteistyÃ¶ssÃ¤ pankkien kanssa.
- Suunnittelet AI-ratkaisuja yhdessÃ¤ muiden asiantuntijoiden kanssa sekÃ¤ luot ja testaat itse tekoÃ¤lymalleja.
- KehitÃ¤t edistyksellistÃ¤, ennustavaa analytiikkaa yhdessÃ¤ tiimin analyytikkojen kanssa.
- Jalostat AI-kehittÃ¤miskÃ¤ytÃ¤ntÃ¶jÃ¤ osaksi organisaation toimintamalleja.
- Tutkit ja analysoit prosesseista ja datasta esiin uusia kehitysmahdollisuuksia.
- Tuet POP Pankki -ryhmÃ¤n Data- ja TekoÃ¤lystrategiaa.
- Toimit sisÃ¤isenÃ¤ AI-asiantuntijana ja kouluttajana.

Odotukset:
- Seuraat AI-teknologioiden kehittymistÃ¤ ja sovellat niitÃ¤ kÃ¤ytÃ¤ntÃ¶Ã¶n.
- Tunnistat hyÃ¶dyntÃ¤mismahdollisuuksia datasta ja prosesseista.
- YmmÃ¤rrÃ¤t ML/AI:n ja osaat toteuttaa ratkaisuja palveluihin ja prosesseihin.
- Kokemusta edistyksellisestÃ¤ analytiikasta.
- Tunnet Googlen Data- ja AI-teknologiat sekÃ¤ Microsoft Copilotin ja sinulla on kokemusta niiden hyÃ¶dyntÃ¤misestÃ¤.
- Tunnet kehittÃ¤mismenetelmiÃ¤; yhteistyÃ¶ sujuu sidosryhmien kanssa.
- Hallitset projektityÃ¶skentelyn; hyvÃ¤t vuorovaikutus- ja koulutustaidot.
- Eduksi: AI governance, regulaatio (EU AI Act) ja niiden soveltaminen kÃ¤ytÃ¤ntÃ¶Ã¶n.
"""

# Persona / system-prompt lyhyenÃ¤
PERSONA = """
SinÃ¤ olet POP Pankin AI Advisor -roolin tukena toimiva AI-agentti.
Vastaa suomeksi (ellei kÃ¤yttÃ¤jÃ¤ vaihda kieltÃ¤) selkeÃ¤sti, konkreettisesti ja ehdota askelmerkkejÃ¤.
Korosta mitattavia hyÃ¶tyjÃ¤, riskejÃ¤ ja governance-kÃ¤ytÃ¤ntÃ¶jÃ¤. VÃ¤ltÃ¤ hypeÃ¤.
"""

# -------------------------------
# In-memory "vektorikauppa"
# -------------------------------
@dataclass
class Chunk:
    doc_id: str
    text: str
    vector: np.ndarray
    meta: Dict[str, Any]

class MiniStore:
    def __init__(self):
        self.chunks: List[Chunk] = []

    def add_doc(self, doc_id: str, text: str, embedder: Optional[Callable[[str], np.ndarray]], meta: Dict[str, Any]):
        for piece in split_into_chunks(text, 1200):
            vec = None
            if embedder is not None:
                try:
                    vec = embedder(piece)
                except Exception:
                    vec = None
            if vec is None:
                # Fallback vektori, jotta appi ei kaadu quota-/avainongelmissa
                vec = np.zeros(8, dtype=np.float32)
            self.chunks.append(Chunk(doc_id=doc_id, text=piece, vector=vec, meta=meta))

    def search(self, query: str, embedder: Optional[Callable[[str], np.ndarray]], k: int = 5):
        if not self.chunks:
            return []
        qv = None
        if embedder is not None:
            try:
                qv = embedder(query)
            except Exception:
                qv = None

        if qv is not None and np.linalg.norm(qv) > 0:
            # Embedding-haku
            scores = [(cosine_sim(qv, ch.vector), ch) for ch in self.chunks]
        else:
            # Fallback: yksinkertainen avainsanapisteytys
            qwords = [w for w in query.lower().split() if len(w) > 2]
            def kw_score(txt: str):
                lt = txt.lower()
                return sum(lt.count(w) for w in qwords) if qwords else 0
            scores = [(kw_score(ch.text), ch) for ch in self.chunks]

        scores.sort(key=lambda x: x[0], reverse=True)
        return [c for _, c in scores[:k]]

# -------------------------------
# OpenAI-apurit
# -------------------------------
_client_cache = {}

def get_client(api_key: str | None = None) -> OpenAI:
    key = api_key or os.getenv("OPENAI_API_KEY", "")
    if not key:
        raise RuntimeError("OPENAI_API_KEY ei ole asetettu. LisÃ¤Ã¤ se sivupalkissa tai ympÃ¤ristÃ¶muuttujana.")
    if key in _client_cache:
        return _client_cache[key]
    cli = OpenAI(api_key=key)
    _client_cache[key] = cli
    return cli

def embed_text(text: str, client: OpenAI) -> np.ndarray:
    text = text.replace("\n", " ")
    try:
        emb = client.embeddings.create(model=EMBED_MODEL, input=[text]).data[0].embedding
        return np.array(emb, dtype=np.float32)
    except Exception:
        # Fallback nollavektori â†’ ei kaatumista quota-virheissÃ¤
        st.session_state["embed_fallback"] = True
        return np.zeros(8, dtype=np.float32)

def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:
    denom = (np.linalg.norm(a) * np.linalg.norm(b)) or 1e-8
    return float(np.dot(a, b) / denom)

def split_into_chunks(text: str, max_chars: int) -> List[str]:
    text = " ".join(text.split())
    out, buf, count = [], [], 0
    for token in text.split(" "):
        if count + len(token) + 1 > max_chars:
            out.append(" ".join(buf))
            buf, count = [token], len(token)
        else:
            buf.append(token)
            count += len(token) + 1
    if buf:
        out.append(" ".join(buf))
    return out

def read_pdf(file: io.BytesIO) -> str:
    reader = PdfReader(file)
    parts = []
    for page in reader.pages:
        try:
            parts.append(page.extract_text() or "")
        except Exception:
            pass
    return "\n".join(parts)

# -------------------------------
# Pienet tyÃ¶kalut (bullets)
# -------------------------------
def tool_bullets_ai_opportunities() -> str:
    return "\n".join([
        "1) Asiakaspalvelu Copilot: summaus, vastaus-ehdotukset, CRM-kirjaus.",
        "2) Fraud score (rules+ML): signaalifuusio, SHAP-seuranta.",
        "3) AML alert triage: priorisointi + tutkintamuistion runko.",
        "4) Ennustava luotonanto: PD/LGD + selitettÃ¤vyys-paneeli.",
        "5) TietopyyntÃ¶jen automaatio: ohjattu haku, audit-logi.",
        "6) SisÃ¤inen RAG-haku: ohjeet, prosessit, mallidokit.",
    ])

def tool_ai_governance_checklist() -> str:
    return "\n".join([
        "â€¢ Data governance: omistajuus, laatu, sÃ¤ilytys, DPIA tarpeen mukaan.",
        "â€¢ Mallien elinkaari: versiointi, hyvÃ¤ksyntÃ¤, monitorointi (drift/bias).",
        "â€¢ SelitettÃ¤vyys: SHAP/LIME tai policy, milloin vaaditaan.",
        "â€¢ EU AI Act: luokitus, kontrollit, rekisterÃ¶inti tarvittaessa.",
        "â€¢ Riskienhallinta: human-in-the-loop, fallback, vaikutusarvio.",
        "â€¢ Tietoturva & pÃ¤Ã¤synhallinta: salaisuudet, auditointi.",
    ])

# -------------------------------
# Safe chat + local fallback
# -------------------------------
def local_demo_response(query: str, context: str) -> str:
    bullets = tool_bullets_ai_opportunities()
    gov = tool_ai_governance_checklist()
    plan = (
        "### 30/60/90 pÃ¤ivÃ¤n suunnitelma\n"
        "- **30 pv**: Kartoitus (kÃ¤yttÃ¶tapaukset, datalÃ¤hteet), nopea POC (asiakaspalvelu Copilot tai sisÃ¤inen RAG), governance-periaatteet ja hyvÃ¤ksymiskriteerit.\n"
        "- **60 pv**: POC â†’ pilotiksi, mittarit (SLA/CSAT/TTFR/fraud-precision), monitorointi (drift/bias), dokumentaatio ja koulutus.\n"
        "- **90 pv**: Skaalaus (lisÃ¤tiimit/prosessit), kustannus/vaikutusanalyysi, backlogin priorisointi, tuotantoprosessi (MLOps/LLMOps).\n"
    )
    ctx_note = f"> **Konteksti (poimintoja):**\n{context[:1000]}\n\n" if context else ""
    return (
        "#### Paikallinen demotila (ei OpenAI-vastauksia)\n"
        "OpenAI-kutsu ei ole kÃ¤ytettÃ¤vissÃ¤ (avain/kiintiÃ¶/verkko). Alla ehdotuksia demoa varten:\n\n"
        f"{ctx_note}"
        "#### Pankin AI-mahdollisuudet\n"
        f"{bullets}\n\n"
        "#### AI governance â€“ muistilista\n"
        f"{gov}\n\n"
        f"{plan}"
        "PyydÃ¤ tÃ¤ydentÃ¤mÃ¤Ã¤n yksityiskohdat tai lataamaan dokumentteja (PDF/TXT), niin demo viittaa niihin RAG-haulla."
    )

def safe_chat_completion(client: OpenAI, model: str, messages: list, temperature: float = 0.3):
    try:
        return client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
        )
    except Exception:
        # Ã„lÃ¤ kaada sovellusta, kerro mitÃ¤ tapahtui ja palauta None
        st.warning("OpenAI-chat ei ole kÃ¤ytettÃ¤vissÃ¤ (avain/kiintiÃ¶/verkko). NÃ¤ytetÃ¤Ã¤n paikallinen demovastaus.")
        return None

# -------------------------------
# UI
# -------------------------------
st.set_page_config(page_title=APP_NAME, page_icon="ðŸ¤–")
st.title(APP_NAME)

with st.sidebar:
    st.subheader("Asetukset")
    api_key = st.text_input("OPENAI_API_KEY", value=os.getenv("OPENAI_API_KEY", ""), type="password")
    model = st.text_input("Chat-malli", value=DEFAULT_MODEL)
    st.markdown("---")
    st.caption("LisÃ¤Ã¤ dokumentteja (PDF/TXT) â€” indeksoidaan paikallisesti.")
    up_files = st.file_uploader("LisÃ¤Ã¤ dokumentteja", type=["pdf", "txt"], accept_multiple_files=True)
    if st.button("TyhjennÃ¤ keskustelu"):
        st.session_state.pop("messages", None)

client: Optional[OpenAI] = None
if api_key:
    try:
        client = get_client(api_key)
    except Exception as e:
        st.error(str(e))

if "store" not in st.session_state:
    st.session_state.store = MiniStore()
if "bootstrapped" not in st.session_state:
    st.session_state.bootstrapped = False

store: MiniStore = st.session_state.store

# Bootstrap: lisÃ¤tÃ¤Ã¤n job ad (+ tyhjÃ¤ ABOUT_ME)
if not st.session_state.bootstrapped:
    emb_fn = (lambda txt: embed_text(txt, client)) if client else None
    store.add_doc("job_ad", JOB_TEXT, emb_fn, {"source": "job_ad"})
    if ABOUT_ME.strip():
        store.add_doc("about_me", ABOUT_ME, emb_fn, {"source": "about_me"})
    st.session_state.bootstrapped = True

# Banneri, jos embeddings fallback on pÃ¤Ã¤llÃ¤
if st.session_state.get("embed_fallback"):
    st.info("Embeddings ei kÃ¤ytettÃ¤vissÃ¤ (avain/kiintiÃ¶). Haku toimii avainsanoilla, chatilla on paikallinen fallback.")

# Uploadit
if up_files:
    emb_fn = (lambda txt: embed_text(txt, client)) if client else None
    for f in up_files:
        text = read_pdf(io.BytesIO(f.getvalue())) if f.type == "application/pdf" else f.getvalue().decode("utf-8", errors="ignore")
        store.add_doc(f.name, text, emb_fn, {"source": f.name})
    st.success(f"Indeksoitu {len(up_files)} tiedosto(a).")

# Keskustelutila
if "messages" not in st.session_state:
    st.session_state.messages = []

def build_context(query: str) -> str:
    emb_fn = (lambda txt: embed_text(txt, client)) if client else None
    h
