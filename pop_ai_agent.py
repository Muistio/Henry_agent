#!/usr/bin/env python3
"""
Pop AI Advisor ‚Äì Personal Agent Demo (Streamlit)
------------------------------------------------
Kevyt Streamlit-sovellus, jolla POP Pankin rekry voi jutella AI-agentin kanssa.
N√§ytt√§√§:
  ‚Ä¢ Persona + keskustelumuisti
  ‚Ä¢ RAG ty√∂paikkailmoituksesta + (valinnaisesti) ladatuista tiedostoista
  ‚Ä¢ Pienet ty√∂kalut (AI-ideat, roadmap-bulletit, AI governance -checklist)

Pika-aloitus:
1) pip install -U -r requirements.txt
2) export OPENAI_API_KEY=...  (tai aseta sivupalkissa)
3) streamlit run pop_ai_agent.py
"""

import io
import os
from dataclasses import dataclass
from typing import List, Dict, Any, Optional, Callable

import numpy as np
import streamlit as st
from openai import OpenAI
from pypdf import PdfReader

# -------------------------------
# Perusasetukset
# -------------------------------
DEFAULT_MODEL = "gpt-4o-mini"
EMBED_MODEL = "text-embedding-3-small"
APP_NAME = "Pop AI advisor ‚Äì agent"

# Ei henkil√∂kohtaisia tietoja
ABOUT_ME = """"""

# Ty√∂paikkailmoitus (ydin)
JOB_TEXT = """
Haemme POP Pankkikeskukseen: AI Advisor (AI-asiantuntijaa)

AI Advisorin keskeiset teht√§v√§t:
- Suunnittelet ja koordinoit pankkiryhm√§n teko√§lykehityst√§ tiiviiss√§ yhteisty√∂ss√§ pankkien kanssa.
- Suunnittelet AI-ratkaisuja yhdess√§ muiden asiantuntijoiden kanssa sek√§ luot ja testaat itse teko√§lymalleja.
- Kehit√§t edistyksellist√§, ennustavaa analytiikkaa yhdess√§ tiimin analyytikkojen kanssa.
- Jalostat AI-kehitt√§misk√§yt√§nt√∂j√§ osaksi organisaation toimintamalleja.
- Tutkit ja analysoit prosesseista ja datasta esiin uusia kehitysmahdollisuuksia.
- Tuet POP Pankki -ryhm√§n Data- ja Teko√§lystrategiaa.
- Toimit sis√§isen√§ AI-asiantuntijana ja kouluttajana.

Odotukset:
- Seuraat AI-teknologioiden kehittymist√§ ja sovellat niit√§ k√§yt√§nt√∂√∂n.
- Tunnistat hy√∂dynt√§mismahdollisuuksia datasta ja prosesseista.
- Ymm√§rr√§t ML/AI:n ja osaat toteuttaa ratkaisuja palveluihin ja prosesseihin.
- Kokemusta edistyksellisest√§ analytiikasta.
- Tunnet Googlen Data- ja AI-teknologiat sek√§ Microsoft Copilotin ja sinulla on kokemusta niiden hy√∂dynt√§misest√§.
- Tunnet kehitt√§mismenetelmi√§; yhteisty√∂ sujuu sidosryhmien kanssa.
- Hallitset projektity√∂skentelyn; hyv√§t vuorovaikutus- ja koulutustaidot.
- Eduksi: AI governance, regulaatio (EU AI Act) ja niiden soveltaminen k√§yt√§nt√∂√∂n.
"""

# Persona / system-prompt lyhyen√§
PERSONA = """
Sin√§ olet POP Pankin AI Advisor -roolin tukena toimiva AI-agentti.
Vastaa suomeksi (ellei k√§ytt√§j√§ vaihda kielt√§) selke√§sti, konkreettisesti ja ehdota askelmerkkej√§.
Korosta mitattavia hy√∂tyj√§, riskej√§ ja governance-k√§yt√§nt√∂j√§. V√§lt√§ hype√§.
"""

# -------------------------------
# In-memory "vektorikauppa"
# -------------------------------
@dataclass
class Chunk:
    doc_id: str
    text: str
    vector: np.ndarray
    meta: Dict[str, Any]

class MiniStore:
    def __init__(self):
        self.chunks: List[Chunk] = []

    def add_doc(self, doc_id: str, text: str, embedder: Optional[Callable[[str], np.ndarray]], meta: Dict[str, Any]):
        for piece in split_into_chunks(text, 1200):
            vec = None
            if embedder is not None:
                try:
                    vec = embedder(piece)
                except Exception:
                    vec = None
            if vec is None:
                # Fallback vektori, jotta appi ei kaadu quota-/avainongelmissa
                vec = np.zeros(8, dtype=np.float32)
            self.chunks.append(Chunk(doc_id=doc_id, text=piece, vector=vec, meta=meta))

    def search(self, query: str, embedder: Optional[Callable[[str], np.ndarray]], k: int = 5):
        if not self.chunks:
            return []
        qv = None
        if embedder is not None:
            try:
                qv = embedder(query)
            except Exception:
                qv = None

        if qv is not None and np.linalg.norm(qv) > 0:
            # Embedding-haku
            scores = [(cosine_sim(qv, ch.vector), ch) for ch in self.chunks]
        else:
            # Fallback: yksinkertainen avainsanapisteytys
            qwords = [w for w in query.lower().split() if len(w) > 2]
            def kw_score(txt: str):
                lt = txt.lower()
                return sum(lt.count(w) for w in qwords) if qwords else 0
            scores = [(kw_score(ch.text), ch) for ch in self.chunks]

        scores.sort(key=lambda x: x[0], reverse=True)
        return [c for _, c in scores[:k]]

# -------------------------------
# OpenAI-apurit
# -------------------------------
_client_cache = {}

def get_client(api_key: str | None = None) -> OpenAI:
    key = api_key or os.getenv("OPENAI_API_KEY", "")
    if not key:
        raise RuntimeError("OPENAI_API_KEY ei ole asetettu. Lis√§√§ se sivupalkissa tai ymp√§rist√∂muuttujana.")
    if key in _client_cache:
        return _client_cache[key]
    cli = OpenAI(api_key=key)
    _client_cache[key] = cli
    return cli

def embed_text(text: str, client: OpenAI) -> np.ndarray:
    text = text.replace("\n", " ")
    try:
        emb = client.embeddings.create(model=EMBED_MODEL, input=[text]).data[0].embedding
        return np.array(emb, dtype=np.float32)
    except Exception:
        # Fallback nollavektori ‚Üí ei kaatumista quota-virheiss√§
        st.session_state["embed_fallback"] = True
        return np.zeros(8, dtype=np.float32)

def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:
    denom = (np.linalg.norm(a) * np.linalg.norm(b)) or 1e-8
    return float(np.dot(a, b) / denom)

def split_into_chunks(text: str, max_chars: int) -> List[str]:
    text = " ".join(text.split())
    out, buf, count = [], [], 0
    for token in text.split(" "):
        if count + len(token) + 1 > max_chars:
            out.append(" ".join(buf))
            buf, count = [token], len(token)
        else:
            buf.append(token)
            count += len(token) + 1
    if buf:
        out.append(" ".join(buf))
    return out

def read_pdf(file: io.BytesIO) -> str:
    reader = PdfReader(file)
    parts = []
    for page in reader.pages:
        try:
            parts.append(page.extract_text() or "")
        except Exception:
            pass
    return "\n".join(parts)

# -------------------------------
# Pienet ty√∂kalut (bullets)
# -------------------------------
def tool_bullets_ai_opportunities() -> str:
    return "\n".join([
        "1) Asiakaspalvelu Copilot: summaus, vastaus-ehdotukset, CRM-kirjaus.",
        "2) Fraud score (rules+ML): signaalifuusio, SHAP-seuranta.",
        "3) AML alert triage: priorisointi + tutkintamuistion runko.",
        "4) Ennustava luotonanto: PD/LGD + selitett√§vyys-paneeli.",
        "5) Tietopyynt√∂jen automaatio: ohjattu haku, audit-logi.",
        "6) Sis√§inen RAG-haku: ohjeet, prosessit, mallidokit.",
    ])

def tool_ai_governance_checklist() -> str:
    return "\n".join([
        "‚Ä¢ Data governance: omistajuus, laatu, s√§ilytys, DPIA tarpeen mukaan.",
        "‚Ä¢ Mallien elinkaari: versiointi, hyv√§ksynt√§, monitorointi (drift/bias).",
        "‚Ä¢ Selitett√§vyys: SHAP/LIME tai policy, milloin vaaditaan.",
        "‚Ä¢ EU AI Act: luokitus, kontrollit, rekister√∂inti tarvittaessa.",
        "‚Ä¢ Riskienhallinta: human-in-the-loop, fallback, vaikutusarvio.",
        "‚Ä¢ Tietoturva & p√§√§synhallinta: salaisuudet, auditointi.",
    ])

# -------------------------------
# Safe chat + local fallback
# -------------------------------
def local_demo_response(query: str, context: str) -> str:
    bullets = tool_bullets_ai_opportunities()
    gov = tool_ai_governance_checklist()
    plan = (
        "### 30/60/90 p√§iv√§n suunnitelma\n"
        "- **30 pv**: Kartoitus (k√§ytt√∂tapaukset, datal√§hteet), nopea POC (asiakaspalvelu Copilot tai sis√§inen RAG), governance-periaatteet ja hyv√§ksymiskriteerit.\n"
        "- **60 pv**: POC ‚Üí pilotiksi, mittarit (SLA/CSAT/TTFR/fraud-precision), monitorointi (drift/bias), dokumentaatio ja koulutus.\n"
        "- **90 pv**: Skaalaus (lis√§tiimit/prosessit), kustannus/vaikutusanalyysi, backlogin priorisointi, tuotantoprosessi (MLOps/LLMOps).\n"
    )
    ctx_note = f"> **Konteksti (poimintoja):**\n{context[:1000]}\n\n" if context else ""
    return (
        "#### Paikallinen demotila (ei OpenAI-vastauksia)\n"
        "OpenAI-kutsu ei ole k√§ytett√§viss√§ (avain/kiinti√∂/verkko). Alla ehdotuksia demoa varten:\n\n"
        f"{ctx_note}"
        "#### Pankin AI-mahdollisuudet\n"
        f"{bullets}\n\n"
        "#### AI governance ‚Äì muistilista\n"
        f"{gov}\n\n"
        f"{plan}"
        "Pyyd√§ t√§ydent√§m√§√§n yksityiskohdat tai lataamaan dokumentteja (PDF/TXT), niin demo viittaa niihin RAG-haulla."
    )

def safe_chat_completion(client: OpenAI, model: str, messages: list, temperature: float = 0.3):
    try:
        return client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
        )
    except Exception:
        # √Ñl√§ kaada sovellusta, kerro mit√§ tapahtui ja palauta None
        st.warning("OpenAI-chat ei ole k√§ytett√§viss√§ (avain/kiinti√∂/verkko). N√§ytet√§√§n paikallinen demovastaus.")
        return None

# -------------------------------
# UI
# -------------------------------
st.set_page_config(page_title=APP_NAME, page_icon="ü§ñ")
st.title(APP_NAME)

with st.sidebar:
    st.subheader("Asetukset")
    api_key = st.text_input("OPENAI_API_KEY", value=os.getenv("OPENAI_API_KEY", ""), type="password")
    model = st.text_input("Chat-malli", value=DEFAULT_MODEL)
    st.markdown("---")
    st.caption("Lis√§√§ dokumentteja (PDF/TXT) ‚Äî indeksoidaan paikallisesti.")
    up_files = st.file_uploader("Lis√§√§ dokumentteja", type=["pdf", "txt"], accept_multiple_files=True)
    if st.button("Tyhjenn√§ keskustelu"):
        st.session_state.pop("messages", None)

client: Optional[OpenAI] = None
if api_key:
    try:
        client = get_client(api_key)
    except Exception as e:
        st.error(str(e))

if "store" not in st.session_state:
    st.session_state.store = MiniStore()
if "bootstrapped" not in st.session_state:
    st.session_state.bootstrapped = False

store: MiniStore = st.session_state.store

# Bootstrap: lis√§t√§√§n job ad (+ tyhj√§ ABOUT_ME)
if not st.session_state.bootstrapped:
    emb_fn = (lambda txt: embed_text(txt, client)) if client else None
    store.add_doc("job_ad", JOB_TEXT, emb_fn, {"source": "job_ad"})
    if ABOUT_ME.strip():
        store.add_doc("about_me", ABOUT_ME, emb_fn, {"source": "about_me"})
    st.session_state.bootstrapped = True

# Banneri, jos embeddings fallback on p√§√§ll√§
if st.session_state.get("embed_fallback"):
    st.info("Embeddings ei k√§ytett√§viss√§ (avain/kiinti√∂). Haku toimii avainsanoilla, chatilla on paikallinen fallback.")

# Uploadit
if up_files:
    emb_fn = (lambda txt: embed_text(txt, client)) if client else None
    for f in up_files:
        text = read_pdf(io.BytesIO(f.getvalue())) if f.type == "application/pdf" else f.getvalue().decode("utf-8", errors="ignore")
        store.add_doc(f.name, text, emb_fn, {"source": f.name})
    st.success(f"Indeksoitu {len(up_files)} tiedosto(a).")

# Keskustelutila
if "messages" not in st.session_state:
    st.session_state.messages = []

def build_context(query: str) -> str:
    emb_fn = (lambda txt: embed_text(txt, client)) if client else None
    h
